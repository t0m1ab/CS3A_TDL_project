# Experiments with Batch Normalization in Neural Networks

Implementation of most of the experiments described in paper: [Batch Normalization Orthogonalizes Representations in Deep Random Networks](https://arxiv.org/pdf/2106.03970.pdf) written by *Daneshmand et al.*

The code is organized as follows:

* `orthogonality_deep_representations.py` implements the experimentations presented in section 3 of the paper.

* `orthogonality_optimization.py` implements the experimentations presented in section 5 of the paper.

* `figures` contains the plots obtained after running the previous code and are presented below.

### Results

<img src="figures/figure_1.png" alt="fig1" width="500" position/>

*Reproduction of figure 1*

<img src="figures/figure_2a.png" alt="fig2a" width="500" position/>

*Reproduction of figure 2a*

<img src="figures/figure_2b.png" alt="fig2b" width="500" position/>

*Reproduction of figure 2b*

<img src="figures/figure_3a.png" alt="fig3a" width="500" position/>

*Reproduction of figure 3a (single run)*

<img src="figures/figure_3b.png" alt="fig3b" width="500" position/>

*Reproduction of figure 3b (single run)*

<img src="figures/figure_4.png" alt="fig4" width="500" position/>

*Reproduction of figure 4 (single run)*

<img src="figures/figure_2b_relu.png" alt="fig2brelu" width="500" position/>

*Reproduction of figure 2b (with ReLU activation)*

<img src="figures/figure_2b_sigmoid.png" alt="fig2bsigmoid" width="500" position/>

*Reproduction of figure 2b (with sigmoid activation)*

<img src="figures/figure_2b_sin.png" alt="fig2bsin" width="500" position/>

*Reproduction of figure 2b (with sinus activation)*

<img src="figures/figure_2b_tanh.png" alt="fig2btanh" width="500" position/>

*Reproduction of figure 2b (with tanh activation)*